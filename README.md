<aside>
ğŸ’¡ (https://api.opensea.io/api) ì˜ apië¥¼ ì´ìš©í•´ì„œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì— ETL ì €ì¥ì„ í•´ë³´ëŠ” í”„ë¡œì íŠ¸

</aside>

1. í…Œì´ë¸” ìƒì„±
     
    ```python
    from datetime import datetime
    import json
    
    from airflow import DAG
    from airflow.providers.sqlite.operators.sqlite import SqliteOperator
    
    default_args = {
      'start_date': datetime(2023, 1, 1),
    }
    
    # DAG Skeleton 
    with DAG(dag_id='nft-pipeline',
             schedule_interval='@daily', # ì£¼ê¸° ì§€ì •
             default_args=default_args, 
             tags=['nft'],
             catchup=False) as dag:
      pass
      
      creating_table = SqliteOperator(
        task_id='creating_table',
        sqlite_conn_id='db_sqlite',
        # if not exists ì‚¬ìš©
        sql='''
          CREATE TABLE IF NOT EXISTS nfts (
            token_id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            image_url TEXT NOT NULL
          )
        '''
      )
    ```
    
    - airflow íƒœìŠ¤í¬ ì‹¤í–‰ - `2023-02-20`(execution date)
        
        `airflow tasks test nft-pipeline creating_table 2023-02-20`
        
        â‡’ INFO - Marking task as SUCCESS. dag_id=nft-pipeline, task_id=creating_table, execution_date=20230220T000000, start_date=, end_date=20230221T151044 
        
2. API í™•ì¸
     
    ```python
    from airflow.providers.http.sensors.http import HttpSensor
    
    is_api_available = HttpSensor(
        task_id='is_api_available',
        http_conn_id='opensea_api',
        endpoint='api/v1/assets?collection=doodles-official&limit=1'
      )
    ```
    
3. NFT ì •ë³´ ì¶”ì¶œ
    
    [https://api.opensea.io/api/v1/assets?collection=doodles-official&limit=1](https://api.opensea.io/api/v1/assets?collection=doodles-official&limit=1)
    ìœ„ì˜ SimpleHttpOperator****************ë¥¼ í†µí•´**************** api ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ê²ƒì´ë‹¤.
     
    ```python
    extract_nft = SimpleHttpOperator(
        task_id='extract_nft',
        http_conn_id='opensea_api',
        endpoint='api/v1/assets?collection=doodles-official&limit=1',
        method='GET',
        response_filter=lambda res: json.loads(res.text),
        log_response=True
      )
    ```
    
4. NFT ì •ë³´ ê°€ê³µ
    
    `SimpleHttpOperator` ë¡œ ê°€ì ¸ì˜¨ ì •ë³´ë¥¼ ê°€ê³µí•˜ëŠ” task
    
    ë°ì´í„°ê°€ ë„˜ì–´ì˜¤ê²Œ í•˜ë ¤ë©´ `xcom_pull`ì„ ì‚¬ìš©
    
    ```python
    def _processing_nft(ti):
      assets = ti.xcom_pull(task_ids=['extract_nft'])
      if not len(assets):
        raise ValueError("assets is empty")
      nft = assets[0]['assets'][0] # nft asset
    
      processed_nft = json_normalize({
        'token_id': nft['token_id'],
        'name': nft['name'],
        'image_url': nft['image_url'],
      })
      processed_nft.to_csv('/tmp/processed_nft.csv', index=None, header=False)
    
    ## call python processing function
      process_nft = PythonOperator(
        task_id='process_nft',
        python_callable=_processing_nft
      )
    ```
    
5. NFT ì •ë³´ ì €ì¥
    
    `BashOperator` ë¥¼ ì´ìš©í•´ì„œ bash ì»¤ë§¨ë“œë¥¼ í†µí•´ ì¶”ì¶œí•œ csv ë°ì´í„°ë¥¼ sqlite dbì— ì €ì¥í•œë‹¤
    
    ```python
    storing_user = BashOperator(
        task_id='storing_user',
        bash_command='echo -e ".separator ","\n.import /tmp/processed_user.csv users" | sqlite3 /Users/yoohajun/Airflow/nft.db'
      )
    ```
    
    `echo -e ".separator ","\n.import /tmp/processed_user.csv users" | sqlite3 /Users/yoohajun/Airflow/nft.db`
    
    â‡’ csv íŒŒì¼ì„ ìª¼ê°œì„œ nfts ë¼ëŠ” í…Œì´ë¸”ì— import í•œë‹¤ëŠ” ëª…ë ¹ì–´
    

1. DAG ë‚´ task ì˜ì¡´ì„± ì£¼ì…
    
    ```python
    ## DAG dependency insertion
    creating_table >> is_api_available >> extract_nft >> process_nft >> storing_user
    ```
    
    ê° íƒœìŠ¤í¬ì— `dag` ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ë©´ íƒœìŠ¤í¬ê°€ ë™ì¼í•œ DAG ì¸ìŠ¤í„´ìŠ¤ì™€ ì—°ê²°ë˜ì–´ `>>` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¡œ ê´€ë ¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ë°©ë²• 1.
    
    ```python
    extract_nft = SimpleHttpOperator(
      task_id='extract_nft',
      http_conn_id='opensea_api',
      endpoint='api/v1/assets?collection=doodles-official&limit=1',
      method='GET',
      response_filter=lambda res: json.loads(res.text),
      log_response=True,
      dag=dag # ì¶”ê°€
    )
    ```
    
    ë°©ë²• 2
    
    ```python
    with DAG(dag_id='nft-pipeline',
             schedule_interval='@daily',
             default_args=default_args,
             tags=['nft'],
             catchup=False) as dag:
    ```
     

1. storing task revision
    
    ìœ„ì˜ taskëŠ” ì €ì¥ì„ í•  ë•Œ, token idê°€ ì¤‘ë³µë˜ë©´ ì €ì¥ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤
    
    ì´ë¯¸ ì €ì¥ëœ rowê°€ ì¤‘ë³µë  ì‹œ ì €ì¥ì„ í•˜ì§€ ì•Šê³  echoë¥¼ í†µí•´ íƒˆì¶œë¬¸ì„ ì¶œë ¥í•˜ë„ë¡ í•œë‹¤.
    
    ```python
    storing_user = BashOperator(
        task_id='storing_user',
        bash_command='''\
          if [ "$(sqlite3 /Users/yoohajun/Airflow/nft.db "SELECT COUNT(*) FROM nfts WHERE token_id='{{ ti.xcom_pull(task_ids='process_nft')['token_id'] }}'")" -eq 0 ]; then \
            echo -e ".separator ','\n.import /tmp/processed_nft.csv nfts" | sqlite3 /Users/yoohajun/Airflow/nft.db; \
          else \
            echo "Token ID {{ ti.xcom_pull(task_ids='process_nft')['token_id'] }} already exists in nfts table"; \
          fi
        '''
      )
    ```
    
2. Backfill ë¬¸ì œ
    
    ë§¤ì¼ ì£¼ê¸°ì ìœ¼ë¡œ ëŒì•„ê°€ëŠ” íŒŒì´í”„ë¼ì¸ì„ ë©ˆì·„ë‹¤ê°€ ëª‡ ì¼ ë’¤ì— ì‹¤í–‰ì‹œí‚¤ë©´ ì–´ë–»ê²Œ ë ê¹Œ?
    
    DAG ìŠ¤ì¼ˆë ˆí†¤ ë‚´ì— catch up íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤.
    
    start dateë¶€í„° backfillì„ ì‹¤í–‰í•  ê²ƒì´ë‹¤.
    
    ë§ˆì§€ë§‰ìœ¼ë¡œ ëŒë¦¬ì§€ ëª»í–ˆë˜ dagë¶€í„° backfillì„ ì‹œë„ â‡’ ë°€ë ¸ë˜ ëª‡ ê°œì˜ DAGë¥¼ íì— ë„£ì–´ ì‹¤í–‰í•  ê²ƒì´ë‹¤.
